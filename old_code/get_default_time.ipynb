{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seed for any random operations\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test dataset (TODO: test data being used is temporary. replace with final test data.)\n",
    "\n",
    "train = pd.read_csv(\"sorted_train0314.csv\")\n",
    "test = pd.read_csv(\"sorted_test0314.csv\")\n",
    "val = pd.read_csv(\"sorted_val0314.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of simulations we want\n",
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event time simulation\n",
    "def get_default_time(loan, hazard_model, thre):\n",
    "    # sample from a uniform distrbution\n",
    "    u = np.random.rand()\n",
    "    t = hazard_model(loan) # get the distribution\n",
    "    idx = np.array(t.index.tolist())\n",
    "    val = np.array(t.values.tolist())\n",
    "    idx = np.reshape(idx, (len(idx), 1))\n",
    "    dist = np.concatenate((idx, val), axis=1)\n",
    "    def search(u, dist, thre):\n",
    "        l = 0\n",
    "        r = len(dist)-1\n",
    "        while l < r and r > 0 and l < len(dist)-1:\n",
    "            mid = l + (r - l)/2\n",
    "            if abs(dist[mid][1] - u) < thre:\n",
    "                return dist[mid][0]\n",
    "            elif dist[mid][1] - u> 0:\n",
    "                l = mid + 1\n",
    "            else:\n",
    "                r = mid - 1\n",
    "            \n",
    "    default_time = search(u, dist, thre)\n",
    "    \n",
    "    return default_time\n",
    "\n",
    "# to use :\n",
    "# t = get_default_time(x_train_death[15:16].drop(['DaysToDefault','Default?'], axis = 1),\\\n",
    "#                      cph.predict_survival_function, 0.001)\n",
    "# returns number of days - can be saved in duration column for predicting loss ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates loss of a loan using loss distribution model\n",
    "def calculate_loss(loan):\n",
    "    # PLUG IN LOSS DISTRIBUTION MODEL HERE\n",
    "    return 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulates total loss of 500 loans for a t year horizon\n",
    "def simulate_total_loss(N, years):\n",
    "    total_losses = []\n",
    "    total_loan_amounts = []\n",
    "    for n in range(0, N):\n",
    "        sampled_loans = test_data.sample(500)\n",
    "        cur_loss = 0.0\n",
    "        \n",
    "        for i in range(0, 500):\n",
    "            cur_loan = sampled_loans[i:i+1]\n",
    "            if is_defaulted_by(cur_loan, years=1):\n",
    "                loan_loss = calculate_loss(cur_loan)\n",
    "                cur_loss += loan_loss\n",
    "        \n",
    "        total_losses.append(cur_loss)\n",
    "        total_loan_amounts.append(sampled_loans['GrossApproval'].sum())\n",
    "    \n",
    "    return total_losses, total_loan_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# QUESTION: Should we remove samples where no loans have defaulted? Are we focused on \n",
    "# only loan pools that have defaults or all loan pools in general?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate for 1 year and plot histogram\n",
    "total_1_year_losses, total_1_year_loan_amounts = simulate_total_loss(N, 1)\n",
    "sns.distplot(total_1_year_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat for 5 year and plot histogram\n",
    "total_5_year_losses, total_5_year_loan_amounts = simulate_total_loss(N, 5)\n",
    "sns.distplot(total_5_year_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate VaR of sorted list of values\n",
    "def get_VAR(sorted_losses, level):\n",
    "    index = int((1-level) * 500)\n",
    "    return sorted_losses[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Average VaR of sorted list of values\n",
    "def get_avg_VAR(sorted_losses, level):\n",
    "    index = int((1-level) * 500)\n",
    "    return np.mean(sorted_losses[:index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate confidence interval\n",
    "def get_conf_interval(sample, level=0.95):\n",
    "    n, min_max, mean, var, skew, kurt = stats.describe(sample)\n",
    "    std = math.sqrt(var)\n",
    "    return stats.norm.interval(level, loc=mean, scale=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bootstrap to calculate VaR and Average VaR with confidence intervals\n",
    "def bootstrap_vars(N, total_losses, level=0.95):\n",
    "    losses_df = pd.Series(total_losses)\n",
    "    VaR_samples = []\n",
    "    AVaR_samples = []\n",
    "    \n",
    "    for i in range(0, N):\n",
    "        bootstrap_sample = sorted(losses_df.sample(500, replace=True).tolist())\n",
    "        VaR = get_VAR(bootstrap_sample, level)\n",
    "        AVaR = get_avg_VAR(bootstrap_sample, level)\n",
    "        VaR_samples.append(VaR)\n",
    "        AVaR_samples.append(AVaR)\n",
    "    \n",
    "    print \"VaR estimate (mean):\", np.mean(VaR_samples)\n",
    "    print \"Average VaR estimate (mean):\", np.mean(AVaR_samples)\n",
    "    print \"VaR confidence interval:\", get_conf_interval(VaR_samples, level)\n",
    "    print \"AVaR confidence interval:\", get_conf_interval(AVaR_samples, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of bootstrap simulations\n",
    "B = 1000\n",
    "\n",
    "# Print results\n",
    "print \"1-year loss at 95% level:\"\n",
    "bootstrap_vars(B, total_1_year_losses, 0.95)\n",
    "print \"\"\n",
    "print \"1-year loss at 99% level:\"\n",
    "bootstrap_vars(B, total_1_year_losses, 0.99)\n",
    "print \"\"\n",
    "print \"5-year loss at 95% level:\"\n",
    "bootstrap_vars(B, total_5_year_losses, 0.95)\n",
    "print \"\"\n",
    "print \"5-year loss at 99% level:\"\n",
    "bootstrap_vars(B, total_5_year_losses, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find junior [5%, 15%] and senior tranches [15%, 100%] for 1 year\n",
    "junior_tranche = []\n",
    "senior_tranche = []\n",
    "\n",
    "for i in range(0, N):\n",
    "    loan_amount = total_1_year_loan_amounts[i]\n",
    "    loss_amount = total_1_year_losses[i]\n",
    "    \n",
    "    loss_percentage = float(loss_amount) / loan_amount\n",
    "    junior_loss_percentage = 0.0\n",
    "    senior_loss_percentage = 0.0\n",
    "    \n",
    "    # Loss for junior tranche\n",
    "    if loss_percentage >= 0.05:\n",
    "        if loss_percentage >= 0.15:\n",
    "            junior_loss_percentage = 1.0  # Lost it all\n",
    "        else:\n",
    "            junior_loss_percentage = (loss_percentage - 0.05) / (0.15 - 0.05)\n",
    "    \n",
    "    # Loss for senior tranche\n",
    "    if loss_percentage >= 0.15:\n",
    "        if loss_percentage >= 1.0:\n",
    "            senior_loss_percentage = 1.0  # Lost it all\n",
    "        else:\n",
    "            senior_loss_percentage = (loss_percentage - 0.15) / (1.0 - 0.15)\n",
    "        \n",
    "    junior_tranche.append(junior_loss_percentage)\n",
    "    senior_tranche.append(senior_loss_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot junior histogram\n",
    "j = sns.distplot(junior_tranche)\n",
    "sns.despine()\n",
    "j.axes.set_title('Junior Tranche', fontsize=20, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot senior histogram\n",
    "s = sns.distplot(senior_tranche)\n",
    "sns.despine()\n",
    "s.axes.set_title('Senior Tranche', fontsize=20, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat for 5 year\n",
    "junior_tranche = []\n",
    "senior_tranche = []\n",
    "\n",
    "for i in range(0, N):\n",
    "    loan_amount = total_5_year_loan_amounts[i]\n",
    "    loss_amount = total_5_year_losses[i]\n",
    "    \n",
    "    loss_percentage = float(loss_amount) / loan_amount\n",
    "    junior_loss_percentage = 0.0\n",
    "    senior_loss_percentage = 0.0\n",
    "    \n",
    "    # Loss for junior tranche\n",
    "    if loss_percentage >= 0.05:\n",
    "        if loss_percentage >= 0.15:\n",
    "            junior_loss_percentage = 1.0  # Lost it all\n",
    "        else:\n",
    "            junior_loss_percentage = (loss_percentage - 0.05) / (0.15 - 0.05)\n",
    "    \n",
    "    # Loss for senior tranche\n",
    "    if loss_percentage >= 0.15:\n",
    "        if loss_percentage >= 1.0:\n",
    "            senior_loss_percentage = 1.0  # Lost it all\n",
    "        else:\n",
    "            senior_loss_percentage = (loss_percentage - 0.15) / (1.0 - 0.15)\n",
    "        \n",
    "    junior_tranche.append(junior_loss_percentage)\n",
    "    senior_tranche.append(senior_loss_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot junior histogram\n",
    "j = sns.distplot(junior_tranche)\n",
    "sns.despine()\n",
    "j.axes.set_title('Junior Tranche', fontsize=20, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot senior histogram\n",
    "s = sns.distplot(senior_tranche)\n",
    "sns.despine()\n",
    "s.axes.set_title('Senior Tranche', fontsize=20, alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
